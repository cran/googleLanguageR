<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Mark Edmondson" />

<meta name="date" content="2025-08-02" />

<title>Google Cloud Speech-to-Text API</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Google Cloud Speech-to-Text API</h1>
<h4 class="author">Mark Edmondson</h4>
<h4 class="date">2025-08-02</h4>



<p>The Google Cloud Speech-to-Text API enables you to convert audio to
text by applying neural network models in an easy to use API. The API
recognizes over 80 languages and variants, to support your global user
base. You can transcribe the text of users dictating to an application’s
microphone or enable command-and-control through voice among many other
use cases.</p>
<p>Read more <a href="https://cloud.google.com/speech/">on the Google
Cloud Speech-to-Text Website</a></p>
<p>The Cloud Speech API provides audio transcription. Its accessible via
the <code>gl_speech</code> function.</p>
<p>Arguments include:</p>
<ul>
<li><code>audio_source</code> - this is a local file in the correct
format, or a Google Cloud Storage URI. This can also be a
<code>Wave</code> class object from the package <code>tuneR</code></li>
<li><code>encoding</code> - the format of the sound file -
<code>LINEAR16</code> is the common <code>.wav</code> format, other
formats include <code>FLAC</code> and <code>OGG_OPUS</code></li>
<li><code>sampleRate</code> - this needs to be set to what your file is
recorded at.<br />
</li>
<li><code>languageCode</code> - specify the language spoken as a <a href="https://tools.ietf.org/html/bcp47"><code>BCP-47</code> language
tag</a></li>
<li><code>speechContexts</code> - you can supply keywords to help the
translation with some context.</li>
</ul>
<div id="returned-structure" class="section level3">
<h3>Returned structure</h3>
<p>The API returns a list of two data.frame tibbles -
<code>transcript</code> and <code>timings</code>.</p>
<p>Access them via the returned object and <code>$transcript</code> and
<code>$timings</code></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>return <span class="ot">&lt;-</span> <span class="fu">gl_speech</span>(test_audio, <span class="at">languageCode =</span> <span class="st">&quot;en-GB&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>return<span class="sc">$</span>transcript</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a><span class="co"># A tibble: 1 x 2</span></span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a><span class="co">#                                                                                                         transcript confidence</span></span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a><span class="co">#                                                                                                              &lt;chr&gt;      &lt;chr&gt;</span></span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a><span class="co">#1 to administer medicine to animals is frequently a very difficult matter and yet sometimes it&#39;s necessary to do so  0.9711006</span></span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>return<span class="sc">$</span>timings</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a><span class="co">#   startTime endTime       word</span></span>
<span id="cb1-11"><a href="#cb1-11" tabindex="-1"></a><span class="co">#1         0s  0.100s         to</span></span>
<span id="cb1-12"><a href="#cb1-12" tabindex="-1"></a><span class="co">#2     0.100s  0.700s administer</span></span>
<span id="cb1-13"><a href="#cb1-13" tabindex="-1"></a><span class="co">#3     0.700s  0.700s   medicine</span></span>
<span id="cb1-14"><a href="#cb1-14" tabindex="-1"></a><span class="co">#4     0.700s  1.200s         to</span></span>
<span id="cb1-15"><a href="#cb1-15" tabindex="-1"></a><span class="co"># etc...</span></span></code></pre></div>
</div>
<div id="demo-for-google-cloud-speech-to-text-api" class="section level3">
<h3>Demo for Google Cloud Speech-to-Text API</h3>
<p>A test audio file is installed with the package which reads:</p>
<blockquote>
<p>“To administer medicine to animals is frequently a very difficult
matter, and yet sometimes it’s necessary to do so”</p>
</blockquote>
<p>The file is sourced from the University of Southampton’s speech
detection (<code>http://www-mobile.ecs.soton.ac.uk/</code>) group and is
fairly difficult for computers to parse, as we see below:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">library</span>(googleLanguageR)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="do">## get the sample source file</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>test_audio <span class="ot">&lt;-</span> <span class="fu">system.file</span>(<span class="st">&quot;woman1_wb.wav&quot;</span>, <span class="at">package =</span> <span class="st">&quot;googleLanguageR&quot;</span>)</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="do">## its not perfect but...:)</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="fu">gl_speech</span>(test_audio)<span class="sc">$</span>transcript</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" tabindex="-1"></a><span class="do">## get alternative transcriptions</span></span>
<span id="cb2-9"><a href="#cb2-9" tabindex="-1"></a><span class="fu">gl_speech</span>(test_audio, <span class="at">maxAlternatives =</span> <span class="dv">2</span><span class="dt">L</span>)<span class="sc">$</span>transcript</span>
<span id="cb2-10"><a href="#cb2-10" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" tabindex="-1"></a><span class="fu">gl_speech</span>(test_audio, <span class="at">languageCode =</span> <span class="st">&quot;en-GB&quot;</span>)<span class="sc">$</span>transcript</span>
<span id="cb2-12"><a href="#cb2-12" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" tabindex="-1"></a><span class="do">## help it out with context for &quot;frequently&quot;</span></span>
<span id="cb2-14"><a href="#cb2-14" tabindex="-1"></a><span class="fu">gl_speech</span>(test_audio, </span>
<span id="cb2-15"><a href="#cb2-15" tabindex="-1"></a>            <span class="at">languageCode =</span> <span class="st">&quot;en-GB&quot;</span>, </span>
<span id="cb2-16"><a href="#cb2-16" tabindex="-1"></a>            <span class="at">speechContexts =</span> <span class="fu">list</span>(<span class="at">phrases =</span> <span class="fu">list</span>(<span class="st">&quot;is frequently a very difficult&quot;</span>)))<span class="sc">$</span>transcript</span></code></pre></div>
</div>
<div id="word-transcripts" class="section level3">
<h3>Word transcripts</h3>
<p>The API <a href="https://cloud.google.com/speech/reference/rest/v1/speech/recognize#WordInfo">supports
timestamps</a> on when words are recognised. These are outputted into a
second data.frame that holds three entries: <code>startTime</code>,
<code>endTime</code> and the <code>word</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">str</span>(result<span class="sc">$</span>timings)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="co">#&#39;data.frame&#39;:  152 obs. of  3 variables:</span></span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># $ startTime: chr  &quot;0s&quot; &quot;0.100s&quot; &quot;0.500s&quot; &quot;0.700s&quot; ...</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="co"># $ endTime  : chr  &quot;0.100s&quot; &quot;0.500s&quot; &quot;0.700s&quot; &quot;0.900s&quot; ...</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># $ word     : chr  &quot;a&quot; &quot;Dream&quot; &quot;Within&quot; &quot;A&quot; ...</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>result<span class="sc">$</span>timings</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a><span class="co">#     startTime endTime       word</span></span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co">#1          0s  0.100s          a</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co">#2      0.100s  0.500s      Dream</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="co">#3      0.500s  0.700s     Within</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="co">#4      0.700s  0.900s          A</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="co">#5      0.900s      1s      Dream</span></span></code></pre></div>
</div>
<div id="custom-configurations" class="section level2">
<h2>Custom configurations</h2>
<p>You can also send in other arguments which can help shape the output,
such as speaker diagrization (labelling different speakers) - to use
such custom configurations create a <a href="https://cloud.google.com/speech-to-text/docs/reference/rest/v1p1beta1/RecognitionConfig"><code>RecognitionConfig</code></a>
object. This can be done via R lists which are converted to JSON via
<code>library(jsonlite)</code> and an example is shown below:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="do">## Use a custom configuration</span></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>my_config <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">encoding =</span> <span class="st">&quot;LINEAR16&quot;</span>,</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>                  <span class="at">diarizationConfig =</span> <span class="fu">list</span>(</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>                    <span class="at">enableSpeakerDiarization =</span> <span class="cn">TRUE</span>,</span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>                    <span class="at">minSpeakerCount =</span> <span class="dv">2</span>,</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>                    <span class="at">maxSpeakCount =</span> <span class="dv">3</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>                  ))</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a><span class="co"># languageCode is required, so will be added if not in your custom config</span></span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a><span class="fu">gl_speech</span>(my_audio, <span class="at">languageCode =</span> <span class="st">&quot;en-US&quot;</span>, <span class="at">customConfig =</span> my_config)</span></code></pre></div>
</div>
<div id="asynchronous-calls" class="section level2">
<h2>Asynchronous calls</h2>
<p>For speech files greater than 60 seconds of if you don’t want your
results straight away, set <code>asynch = TRUE</code> in the call to the
API.</p>
<p>This will return an object of class <code>&quot;gl_speech_op&quot;</code> which
should be used within the <code>gl_speech_op()</code> function to check
the status of the task. If the task is finished, then it will return an
object the same form as the non-asynchronous case.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>async <span class="ot">&lt;-</span> <span class="fu">gl_speech</span>(test_audio, <span class="at">asynch =</span> <span class="cn">TRUE</span>)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>async</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="do">## Send to gl_speech_op() for status</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="do">## 4625920921526393240</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>result <span class="ot">&lt;-</span> <span class="fu">gl_speech_op</span>(async)</span></code></pre></div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
