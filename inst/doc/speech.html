<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Mark Edmondson" />

<meta name="date" content="2020-04-19" />

<title>Google Cloud Speech-to-Text API</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Google Cloud Speech-to-Text API</h1>
<h4 class="author">Mark Edmondson</h4>
<h4 class="date">2020-04-19</h4>



<p>The Google Cloud Speech-to-Text API enables you to convert audio to text by applying neural network models in an easy to use API. The API recognizes over 80 languages and variants, to support your global user base. You can transcribe the text of users dictating to an application’s microphone or enable command-and-control through voice among many other use cases.</p>
<p>Read more <a href="https://cloud.google.com/speech/">on the Google Cloud Speech-to-Text Website</a></p>
<p>The Cloud Speech API provides audio transcription. Its accessible via the <code>gl_speech</code> function.</p>
<p>Arguments include:</p>
<ul>
<li><code>audio_source</code> - this is a local file in the correct format, or a Google Cloud Storage URI. This can also be a <code>Wave</code> class object from the package <code>tuneR</code></li>
<li><code>encoding</code> - the format of the sound file - <code>LINEAR16</code> is the common <code>.wav</code> format, other formats include <code>FLAC</code> and <code>OGG_OPUS</code></li>
<li><code>sampleRate</code> - this needs to be set to what your file is recorded at.<br />
</li>
<li><code>languageCode</code> - specify the language spoken as a <a href="https://tools.ietf.org/html/bcp47"><code>BCP-47</code> language tag</a></li>
<li><code>speechContexts</code> - you can supply keywords to help the translation with some context.</li>
</ul>
<div id="returned-structure" class="section level3">
<h3>Returned structure</h3>
<p>The API returns a list of two data.frame tibbles - <code>transcript</code> and <code>timings</code>.</p>
<p>Access them via the returned object and <code>$transcript</code> and <code>$timings</code></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1">return &lt;-<span class="st"> </span><span class="kw">gl_speech</span>(test_audio, <span class="dt">languageCode =</span> <span class="st">&quot;en-GB&quot;</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"></a>
<a class="sourceLine" id="cb1-3" data-line-number="3">return<span class="op">$</span>transcript</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="co"># A tibble: 1 x 2</span></a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co">#                                                                                                         transcript confidence</span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="co">#                                                                                                              &lt;chr&gt;      &lt;chr&gt;</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co">#1 to administer medicine to animals is frequently a very difficult matter and yet sometimes it's necessary to do so  0.9711006</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"></a>
<a class="sourceLine" id="cb1-9" data-line-number="9">return<span class="op">$</span>timings</a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="co">#   startTime endTime       word</span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co">#1         0s  0.100s         to</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="co">#2     0.100s  0.700s administer</span></a>
<a class="sourceLine" id="cb1-13" data-line-number="13"><span class="co">#3     0.700s  0.700s   medicine</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14"><span class="co">#4     0.700s  1.200s         to</span></a>
<a class="sourceLine" id="cb1-15" data-line-number="15"><span class="co"># etc...</span></a></code></pre></div>
</div>
<div id="demo-for-google-cloud-speech-to-text-api" class="section level3">
<h3>Demo for Google Cloud Speech-to-Text API</h3>
<p>A test audio file is installed with the package which reads:</p>
<blockquote>
<p>“To administer medicine to animals is frequently a very difficult matter, and yet sometimes it’s necessary to do so”</p>
</blockquote>
<p>The file is sourced from the University of Southampton’s speech detection (<code>http://www-mobile.ecs.soton.ac.uk/</code>) group and is fairly difficult for computers to parse, as we see below:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">library</span>(googleLanguageR)</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="co">## get the sample source file</span></a>
<a class="sourceLine" id="cb2-3" data-line-number="3">test_audio &lt;-<span class="st"> </span><span class="kw">system.file</span>(<span class="st">&quot;woman1_wb.wav&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;googleLanguageR&quot;</span>)</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"></a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="co">## its not perfect but...:)</span></a>
<a class="sourceLine" id="cb2-6" data-line-number="6"><span class="kw">gl_speech</span>(test_audio)<span class="op">$</span>transcript</a>
<a class="sourceLine" id="cb2-7" data-line-number="7"></a>
<a class="sourceLine" id="cb2-8" data-line-number="8"><span class="co">## get alternative transcriptions</span></a>
<a class="sourceLine" id="cb2-9" data-line-number="9"><span class="kw">gl_speech</span>(test_audio, <span class="dt">maxAlternatives =</span> 2L)<span class="op">$</span>transcript</a>
<a class="sourceLine" id="cb2-10" data-line-number="10"></a>
<a class="sourceLine" id="cb2-11" data-line-number="11"><span class="kw">gl_speech</span>(test_audio, <span class="dt">languageCode =</span> <span class="st">&quot;en-GB&quot;</span>)<span class="op">$</span>transcript</a>
<a class="sourceLine" id="cb2-12" data-line-number="12"></a>
<a class="sourceLine" id="cb2-13" data-line-number="13"><span class="co">## help it out with context for &quot;frequently&quot;</span></a>
<a class="sourceLine" id="cb2-14" data-line-number="14"><span class="kw">gl_speech</span>(test_audio, </a>
<a class="sourceLine" id="cb2-15" data-line-number="15">            <span class="dt">languageCode =</span> <span class="st">&quot;en-GB&quot;</span>, </a>
<a class="sourceLine" id="cb2-16" data-line-number="16">            <span class="dt">speechContexts =</span> <span class="kw">list</span>(<span class="dt">phrases =</span> <span class="kw">list</span>(<span class="st">&quot;is frequently a very difficult&quot;</span>)))<span class="op">$</span>transcript</a></code></pre></div>
</div>
<div id="word-transcripts" class="section level3">
<h3>Word transcripts</h3>
<p>The API <a href="https://cloud.google.com/speech/reference/rest/v1/speech/recognize#WordInfo">supports timestamps</a> on when words are recognised. These are outputted into a second data.frame that holds three entries: <code>startTime</code>, <code>endTime</code> and the <code>word</code>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">str</span>(result<span class="op">$</span>timings)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="co">#'data.frame':  152 obs. of  3 variables:</span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="co"># $ startTime: chr  &quot;0s&quot; &quot;0.100s&quot; &quot;0.500s&quot; &quot;0.700s&quot; ...</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="co"># $ endTime  : chr  &quot;0.100s&quot; &quot;0.500s&quot; &quot;0.700s&quot; &quot;0.900s&quot; ...</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co"># $ word     : chr  &quot;a&quot; &quot;Dream&quot; &quot;Within&quot; &quot;A&quot; ...</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">result<span class="op">$</span>timings</a>
<a class="sourceLine" id="cb3-8" data-line-number="8"><span class="co">#     startTime endTime       word</span></a>
<a class="sourceLine" id="cb3-9" data-line-number="9"><span class="co">#1          0s  0.100s          a</span></a>
<a class="sourceLine" id="cb3-10" data-line-number="10"><span class="co">#2      0.100s  0.500s      Dream</span></a>
<a class="sourceLine" id="cb3-11" data-line-number="11"><span class="co">#3      0.500s  0.700s     Within</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12"><span class="co">#4      0.700s  0.900s          A</span></a>
<a class="sourceLine" id="cb3-13" data-line-number="13"><span class="co">#5      0.900s      1s      Dream</span></a></code></pre></div>
</div>
<div id="custom-configurations" class="section level2">
<h2>Custom configurations</h2>
<p>You can also send in other arguments which can help shape the output, such as speaker diagrization (labelling different speakers) - to use such custom configurations create a <a href="https://cloud.google.com/speech-to-text/docs/reference/rest/v1p1beta1/RecognitionConfig"><code>RecognitionConfig</code></a> object. This can be done via R lists which are converted to JSON via <code>library(jsonlite)</code> and an example is shown below:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="co">## Use a custom configuration</span></a>
<a class="sourceLine" id="cb4-2" data-line-number="2">my_config &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">encoding =</span> <span class="st">&quot;LINEAR16&quot;</span>,</a>
<a class="sourceLine" id="cb4-3" data-line-number="3">                  <span class="dt">diarizationConfig =</span> <span class="kw">list</span>(</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">                    <span class="dt">enableSpeakerDiarization =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb4-5" data-line-number="5">                    <span class="dt">minSpeakerCount =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb4-6" data-line-number="6">                    <span class="dt">maxSpeakCount =</span> <span class="dv">3</span></a>
<a class="sourceLine" id="cb4-7" data-line-number="7">                  ))</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"><span class="co"># languageCode is required, so will be added if not in your custom config</span></a>
<a class="sourceLine" id="cb4-10" data-line-number="10"><span class="kw">gl_speech</span>(my_audio, <span class="dt">languageCode =</span> <span class="st">&quot;en-US&quot;</span>, <span class="dt">customConfig =</span> my_config)</a></code></pre></div>
</div>
<div id="asynchronous-calls" class="section level2">
<h2>Asynchronous calls</h2>
<p>For speech files greater than 60 seconds of if you don’t want your results straight away, set <code>asynch = TRUE</code> in the call to the API.</p>
<p>This will return an object of class <code>&quot;gl_speech_op&quot;</code> which should be used within the <code>gl_speech_op()</code> function to check the status of the task. If the task is finished, then it will return an object the same form as the non-asynchronous case.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1">async &lt;-<span class="st"> </span><span class="kw">gl_speech</span>(test_audio, <span class="dt">asynch =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2">async</a>
<a class="sourceLine" id="cb5-3" data-line-number="3"><span class="co">## Send to gl_speech_op() for status</span></a>
<a class="sourceLine" id="cb5-4" data-line-number="4"><span class="co">## 4625920921526393240</span></a>
<a class="sourceLine" id="cb5-5" data-line-number="5"></a>
<a class="sourceLine" id="cb5-6" data-line-number="6">result &lt;-<span class="st"> </span><span class="kw">gl_speech_op</span>(async)</a></code></pre></div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
